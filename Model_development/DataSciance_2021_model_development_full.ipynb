{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataSciance_model_development_part1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJIscr_tlXH0"
      },
      "source": [
        "# Biblioteki oraz dane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eGI82AdQSNB"
      },
      "source": [
        "#Wczytujemy biblioteki\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import *\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kppnXCBdf2AL"
      },
      "source": [
        "#Wczytujemy dane - baza po obróbce wstępnej, gdzie usunięto puste rekordy oraz duplikaty\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/adamPaclawski/AGH_DataScience_2021/master/Model_development_part1/curated_solubility_database_2021.csv\", index_col=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "yEmtIxztgSAG",
        "outputId": "08403c03-dc3c-4ee6-ea71-2fb85f666e2c"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InChI</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MolWt</th>\n",
              "      <th>MolLogP</th>\n",
              "      <th>MolMR</th>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <th>NumHDonors</th>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <th>RingCount</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>LabuteASA</th>\n",
              "      <th>BalabanJ</th>\n",
              "      <th>BertzCT</th>\n",
              "      <th>logS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>N,N,N-trimethyloctadecan-1-aminium bromide</th>\n",
              "      <td>InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...</td>\n",
              "      <td>SZEMGTQCPRNXEG-UHFFFAOYSA-M</td>\n",
              "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
              "      <td>392.510</td>\n",
              "      <td>3.95810</td>\n",
              "      <td>102.4454</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>158.520601</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>210.377334</td>\n",
              "      <td>-3.616127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2-methyl-N-[(2-methylprop-2-enamido)methyl]prop-2-enamide</th>\n",
              "      <td>InChI=1S/C9H14N2O2/c1-6(2)8(12)10-5-11-9(13)7(...</td>\n",
              "      <td>TURITJIWSQEMDB-UHFFFAOYSA-N</td>\n",
              "      <td>CC(=C)C(=O)NCNC(=O)C(C)=C</td>\n",
              "      <td>182.223</td>\n",
              "      <td>0.32850</td>\n",
              "      <td>50.7804</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.20</td>\n",
              "      <td>77.702350</td>\n",
              "      <td>3.689373</td>\n",
              "      <td>230.340316</td>\n",
              "      <td>-1.189237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1Z,5Z)-cycloocta-1,5-diene</th>\n",
              "      <td>InChI=1S/C8H12/c1-2-4-6-8-7-5-3-1/h1-2,7-8H,3-...</td>\n",
              "      <td>VYXHVRARDIDEHS-QGTKBVGQSA-N</td>\n",
              "      <td>C\\1C\\C=C/CC\\C=C1</td>\n",
              "      <td>108.184</td>\n",
              "      <td>2.67280</td>\n",
              "      <td>36.7480</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>50.908809</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>72.605938</td>\n",
              "      <td>-2.965977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(3-isocyanatopropyl)trimethoxysilane</th>\n",
              "      <td>InChI=1S/C7H15NO4Si/c1-10-13(11-2,12-3)6-4-5-8...</td>\n",
              "      <td>FMGBDYLOANULLW-UHFFFAOYSA-N</td>\n",
              "      <td>CO[Si](CCCN=C=O)(OC)OC</td>\n",
              "      <td>205.286</td>\n",
              "      <td>0.59040</td>\n",
              "      <td>49.1935</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.12</td>\n",
              "      <td>79.077357</td>\n",
              "      <td>3.873429</td>\n",
              "      <td>169.066693</td>\n",
              "      <td>-3.256981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(3-chloropropyl)triethoxysilane</th>\n",
              "      <td>InChI=1S/C9H21ClO3Si/c1-4-11-14(12-5-2,13-6-3)...</td>\n",
              "      <td>KSCAZPYHLGGNPZ-UHFFFAOYSA-N</td>\n",
              "      <td>CCO[Si](CCCCl)(OCC)OCC</td>\n",
              "      <td>240.803</td>\n",
              "      <td>2.66370</td>\n",
              "      <td>60.7760</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.69</td>\n",
              "      <td>93.053663</td>\n",
              "      <td>4.210670</td>\n",
              "      <td>118.205924</td>\n",
              "      <td>-3.328583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tetracaine</th>\n",
              "      <td>InChI=1S/C15H24N2O2/c1-4-5-10-16-14-8-6-13(7-9...</td>\n",
              "      <td>GKCBAIGFKIBETG-UHFFFAOYSA-N</td>\n",
              "      <td>C(c1ccc(cc1)NCCCC)(=O)OCCN(C)C</td>\n",
              "      <td>264.369</td>\n",
              "      <td>2.61700</td>\n",
              "      <td>78.6762</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.57</td>\n",
              "      <td>115.300645</td>\n",
              "      <td>2.394548</td>\n",
              "      <td>374.236893</td>\n",
              "      <td>-3.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tetracycline</th>\n",
              "      <td>InChI=1S/C22H24N2O8/c1-21(31)8-5-4-6-11(25)12(...</td>\n",
              "      <td>OFVLGDICTFRJMM-WESIUVDSSA-N</td>\n",
              "      <td>OC1=C(C(C2=C(O)[C@@](C(C(C(N)=O)=C(O)[C@H]3N(C...</td>\n",
              "      <td>444.440</td>\n",
              "      <td>-0.21440</td>\n",
              "      <td>109.5409</td>\n",
              "      <td>32.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>181.62</td>\n",
              "      <td>182.429237</td>\n",
              "      <td>2.047922</td>\n",
              "      <td>1148.584975</td>\n",
              "      <td>-2.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thymol</th>\n",
              "      <td>InChI=1S/C10H14O/c1-7(2)9-5-4-8(3)6-10(9)11/h4...</td>\n",
              "      <td>MGSRCZKZVOBKFT-UHFFFAOYSA-N</td>\n",
              "      <td>c1(cc(ccc1C(C)C)C)O</td>\n",
              "      <td>150.221</td>\n",
              "      <td>2.82402</td>\n",
              "      <td>46.9328</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.23</td>\n",
              "      <td>67.685405</td>\n",
              "      <td>3.092720</td>\n",
              "      <td>251.049732</td>\n",
              "      <td>-2.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>verapamil</th>\n",
              "      <td>InChI=1S/C27H38N2O4/c1-20(2)27(19-28,22-10-12-...</td>\n",
              "      <td>SGTNSNPWRIOYBX-UHFFFAOYSA-N</td>\n",
              "      <td>COc1ccc(CCN(C)CCCC(C#N)(C(C)C)c2ccc(OC)c(OC)c2...</td>\n",
              "      <td>454.611</td>\n",
              "      <td>5.09308</td>\n",
              "      <td>131.6560</td>\n",
              "      <td>33.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>63.95</td>\n",
              "      <td>198.569223</td>\n",
              "      <td>2.023333</td>\n",
              "      <td>938.203977</td>\n",
              "      <td>-3.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>warfarin</th>\n",
              "      <td>InChI=1S/C19H16O4/c1-12(20)11-15(13-7-3-2-4-8-...</td>\n",
              "      <td>PJVWKTKQMONHTI-UHFFFAOYSA-N</td>\n",
              "      <td>CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O</td>\n",
              "      <td>308.333</td>\n",
              "      <td>3.60960</td>\n",
              "      <td>87.7318</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>67.51</td>\n",
              "      <td>132.552025</td>\n",
              "      <td>2.258072</td>\n",
              "      <td>909.550973</td>\n",
              "      <td>-4.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9882 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                InChI  ...      logS\n",
              "Name                                                                                                   ...          \n",
              "N,N,N-trimethyloctadecan-1-aminium bromide          InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...  ... -3.616127\n",
              "2-methyl-N-[(2-methylprop-2-enamido)methyl]prop...  InChI=1S/C9H14N2O2/c1-6(2)8(12)10-5-11-9(13)7(...  ... -1.189237\n",
              "(1Z,5Z)-cycloocta-1,5-diene                         InChI=1S/C8H12/c1-2-4-6-8-7-5-3-1/h1-2,7-8H,3-...  ... -2.965977\n",
              "(3-isocyanatopropyl)trimethoxysilane                InChI=1S/C7H15NO4Si/c1-10-13(11-2,12-3)6-4-5-8...  ... -3.256981\n",
              "(3-chloropropyl)triethoxysilane                     InChI=1S/C9H21ClO3Si/c1-4-11-14(12-5-2,13-6-3)...  ... -3.328583\n",
              "...                                                                                               ...  ...       ...\n",
              "tetracaine                                          InChI=1S/C15H24N2O2/c1-4-5-10-16-14-8-6-13(7-9...  ... -3.010000\n",
              "tetracycline                                        InChI=1S/C22H24N2O8/c1-21(31)8-5-4-6-11(25)12(...  ... -2.930000\n",
              "thymol                                              InChI=1S/C10H14O/c1-7(2)9-5-4-8(3)6-10(9)11/h4...  ... -2.190000\n",
              "verapamil                                           InChI=1S/C27H38N2O4/c1-20(2)27(19-28,22-10-12-...  ... -3.980000\n",
              "warfarin                                            InChI=1S/C19H16O4/c1-12(20)11-15(13-7-3-2-4-8-...  ... -4.780000\n",
              "\n",
              "[9882 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFZpglg6gke9",
        "outputId": "88628429-af13-4d0b-e7cd-85da7f0c81d7"
      },
      "source": [
        "#Sprawdzamy dla pewności czy wszystkie rekordy zawierają informacje\n",
        "df.isna().sum().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvbRNZ93gwJo",
        "outputId": "f86d87ef-7c87-46c4-bbcb-a614dd79b9ba"
      },
      "source": [
        "#Sprawdzamy, które zmienne nie są numryczne\n",
        "df.dtypes[df.dtypes=='object']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InChI       object\n",
              "InChIKey    object\n",
              "SMILES      object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mURwr76rg8Pw"
      },
      "source": [
        "#Usuwamy zmienne typu object i tworzymy tablicę zawierającą zmienne wejściowe (niezależne)\n",
        "X=df.drop(['InChI', 'InChIKey', 'SMILES', 'logS'], axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYCmEU70hPfK"
      },
      "source": [
        "#Tworzymy też objekt zawierający zmienną zależną: logS\n",
        "Y=df[\"logS\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJHi1smmhZE"
      },
      "source": [
        "# Regresja liniowa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciLulRtYhSfk"
      },
      "source": [
        "#Tworzymy model regresji liniowej z zast. pakietu scikit-learn\n",
        "regLin = linear_model.LinearRegression()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brrSnaHZhtEU",
        "outputId": "a08feb97-a317-4967-8fc6-e3b5d0cb9e39"
      },
      "source": [
        "#Uczymy nasz model - dopasowujemy do danych\n",
        "regLin.fit(y=Y, X=X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "cz6XPEhoiDg_",
        "outputId": "217b20db-9edc-48f6-82d1-b7c23a7bc76a"
      },
      "source": [
        "#Zobaczmy strukturę naszego modelu (wartości współczynników dla poszczególnych zmiennych wejściowych)\n",
        "regLin.coef_\n",
        "results=pd.DataFrame(regLin.coef_, index=X.columns, columns=['Coeff_linReg'])\n",
        "results"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coeff_linReg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MolWt</th>\n",
              "      <td>-0.004690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolLogP</th>\n",
              "      <td>-0.446149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolMR</th>\n",
              "      <td>0.014570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <td>-0.474995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <td>0.107732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHDonors</th>\n",
              "      <td>0.150284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <td>-0.129766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <td>0.042835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <td>0.076472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <td>-0.309124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <td>0.142221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <td>-0.037604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RingCount</th>\n",
              "      <td>-0.346728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TPSA</th>\n",
              "      <td>-0.003299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabuteASA</th>\n",
              "      <td>-0.011001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BalabanJ</th>\n",
              "      <td>-0.023393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BertzCT</th>\n",
              "      <td>0.004553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Coeff_linReg\n",
              "MolWt                   -0.004690\n",
              "MolLogP                 -0.446149\n",
              "MolMR                    0.014570\n",
              "HeavyAtomCount          -0.474995\n",
              "NumHAcceptors            0.107732\n",
              "NumHDonors               0.150284\n",
              "NumHeteroatoms          -0.129766\n",
              "NumRotatableBonds        0.042835\n",
              "NumValenceElectrons      0.076472\n",
              "NumAromaticRings        -0.309124\n",
              "NumSaturatedRings        0.142221\n",
              "NumAliphaticRings       -0.037604\n",
              "RingCount               -0.346728\n",
              "TPSA                    -0.003299\n",
              "LabuteASA               -0.011001\n",
              "BalabanJ                -0.023393\n",
              "BertzCT                  0.004553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cT3aV748i-Ee",
        "outputId": "2a94c09d-a044-4f70-9d40-669c77869e71"
      },
      "source": [
        "#Zestawiamy nasze predykcje oraz wartości obserwowane\n",
        "y_pred=regLin.predict(X)\n",
        "summary=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary[\"Observed\"]=Y.values\n",
        "summary"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Observed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.058858</td>\n",
              "      <td>-3.616127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.407746</td>\n",
              "      <td>-1.189237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.828340</td>\n",
              "      <td>-2.965977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.753258</td>\n",
              "      <td>-3.256981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.682526</td>\n",
              "      <td>-3.328583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9877</th>\n",
              "      <td>-2.750126</td>\n",
              "      <td>-3.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9878</th>\n",
              "      <td>-1.727595</td>\n",
              "      <td>-2.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9879</th>\n",
              "      <td>-2.704118</td>\n",
              "      <td>-2.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9880</th>\n",
              "      <td>-4.015517</td>\n",
              "      <td>-3.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9881</th>\n",
              "      <td>-3.720269</td>\n",
              "      <td>-4.780000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9882 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Predicted  Observed\n",
              "0     -3.058858 -3.616127\n",
              "1     -1.407746 -1.189237\n",
              "2     -2.828340 -2.965977\n",
              "3     -1.753258 -3.256981\n",
              "4     -2.682526 -3.328583\n",
              "...         ...       ...\n",
              "9877  -2.750126 -3.010000\n",
              "9878  -1.727595 -2.930000\n",
              "9879  -2.704118 -2.190000\n",
              "9880  -4.015517 -3.980000\n",
              "9881  -3.720269 -4.780000\n",
              "\n",
              "[9882 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAh4GWImpVL2"
      },
      "source": [
        "# Miary dopasowania - błedu modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvui4L5xlQH0"
      },
      "source": [
        "#Suma kwadratów błędów\n",
        "SSE=(summary['Observed']-summary['Predicted']).pow(2).sum()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69AbY6m4mLUq"
      },
      "source": [
        "#Suma kwadratów błędów jest wrażliwa na ilość rekordów co tworzy trudności dla porównania różnych zbiorów\n",
        "empty=[]\n",
        "for i in range(1,100):\n",
        "  SSE=(summary['Observed'][1000:(1000+i)]-summary['Predicted'][1000:(1000+i)]).pow(2).sum()\n",
        "  empty.append(SSE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzRYU2brmpFZ",
        "outputId": "65680c8b-94a0-4944-ff30-4c403115bc0a"
      },
      "source": [
        "#Wartość średnia sumy kwadratów błędów nie jest wrażliwa na ilość rekordów. Istotny wpływ na jej wartosć mają wartości skrajne\n",
        "MSE=(summary['Observed']-summary['Predicted']).pow(2).sum()/len(summary['Predicted'])\n",
        "MSE"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.719335985359472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_cRT9__nOHj"
      },
      "source": [
        "#Taki sam eksperyment - oczekujemy stabilizacji błędu ze zwiększaniem liczby rekordów\n",
        "empty=[]\n",
        "for i in range(1,100):\n",
        "  MSE=(summary['Observed'][1000:(1000+i)]-summary['Predicted'][1000:(1000+i)]).pow(2).sum()/i\n",
        "  empty.append(MSE)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RroOevRKnUSq",
        "outputId": "8c491b8a-87d3-409c-bbf9-b3b6404f07be"
      },
      "source": [
        "empty"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.797303809225342,\n",
              " 12.010252574860914,\n",
              " 9.695465452082082,\n",
              " 10.30460565474226,\n",
              " 8.79245427129629,\n",
              " 9.548236482029575,\n",
              " 8.329572181986041,\n",
              " 7.628648663707841,\n",
              " 7.029911713599866,\n",
              " 6.416889313082207,\n",
              " 6.508587100502171,\n",
              " 6.054792125726309,\n",
              " 5.656118372937333,\n",
              " 5.331408903013397,\n",
              " 4.976535088853493,\n",
              " 4.674355435313351,\n",
              " 4.403062742003701,\n",
              " 4.1654306524256395,\n",
              " 3.9531906985364493,\n",
              " 3.7932744675830934,\n",
              " 3.628579583806391,\n",
              " 4.161785651722642,\n",
              " 4.031843881632288,\n",
              " 3.868278810969508,\n",
              " 3.811560081213271,\n",
              " 3.7648165606377715,\n",
              " 3.6586969216321497,\n",
              " 3.6851340597306086,\n",
              " 3.6630858553388794,\n",
              " 3.608553451193464,\n",
              " 3.5073633056973486,\n",
              " 3.423087766455758,\n",
              " 3.326450845935132,\n",
              " 3.522452977364838,\n",
              " 3.4637831046837015,\n",
              " 3.5331283204003814,\n",
              " 3.7457646221852556,\n",
              " 3.6537278715798562,\n",
              " 3.5766000207828337,\n",
              " 3.5338631964743525,\n",
              " 3.49321109530287,\n",
              " 3.4488244911323442,\n",
              " 3.582823883214894,\n",
              " 3.5513061645385373,\n",
              " 3.50999275867066,\n",
              " 3.4471609044992153,\n",
              " 3.5391836261822722,\n",
              " 3.5035081814887516,\n",
              " 3.6901988677936512,\n",
              " 3.7204402388953897,\n",
              " 3.677377844210565,\n",
              " 3.6185317279661353,\n",
              " 3.550607261450504,\n",
              " 3.5494996199616025,\n",
              " 3.5779759583491337,\n",
              " 3.520533731102291,\n",
              " 3.5300692562812723,\n",
              " 3.470426725101211,\n",
              " 3.411614870625177,\n",
              " 3.376370192208523,\n",
              " 3.3402444553883277,\n",
              " 3.3135603624118355,\n",
              " 3.2896560969897575,\n",
              " 3.259469845097426,\n",
              " 3.2532024383379006,\n",
              " 3.2729034784241504,\n",
              " 3.2297373463944266,\n",
              " 3.2713069087973405,\n",
              " 3.308497216705237,\n",
              " 3.2621992368921258,\n",
              " 3.519627826613007,\n",
              " 3.606120536466948,\n",
              " 3.5798353554743874,\n",
              " 4.111112623659532,\n",
              " 4.068210588099313,\n",
              " 4.096890139691613,\n",
              " 4.089877037209634,\n",
              " 4.052744415426173,\n",
              " 4.177905250945997,\n",
              " 4.157471297999886,\n",
              " 4.116646871724176,\n",
              " 4.101359418068605,\n",
              " 4.087742743865536,\n",
              " 4.120273294847191,\n",
              " 4.08875958991093,\n",
              " 4.0469393405192555,\n",
              " 4.02601360627568,\n",
              " 4.05092986454681,\n",
              " 4.054654954841355,\n",
              " 4.0324772524183805,\n",
              " 4.046082274057669,\n",
              " 4.012210955041872,\n",
              " 3.97017174729854,\n",
              " 3.937498216310485,\n",
              " 3.9313893239942552,\n",
              " 3.943387948587109,\n",
              " 3.909550164394567,\n",
              " 3.915297090735904,\n",
              " 3.8868477014092497]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dxzjfypoNYJ",
        "outputId": "58682cce-5be1-455a-9bed-5d2aab107774"
      },
      "source": [
        "#Spierwiastkowana średnia sumy kwadratów błędów nie jest wrażliwa na ilość rekordów oraz jest mniej wrażliwa na wartosci skrajne. Ponadto mamy zgodność jednostek względem wartości obserwowanych.\n",
        "RMSE=((summary['Observed']-summary['Predicted']).pow(2).sum()/len(summary['Predicted']))**0.5\n",
        "RMSE"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.649040928952181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeRaflHdo-4S",
        "outputId": "61a55ff8-253d-4b34-fc2c-f39933d7ed85"
      },
      "source": [
        "#Analizując błąd RMSE oraz zakres wartości zmiennej wyjściowej możemy oszacować wartość błędu wyrażonego jako % odległości pomiędzy wartościami min i maks\n",
        "Y.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    9882.000000\n",
              "mean       -2.885159\n",
              "std         2.375397\n",
              "min       -13.171900\n",
              "25%        -4.330000\n",
              "50%        -2.600000\n",
              "75%        -1.199375\n",
              "max         2.137682\n",
              "Name: logS, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXa6McdpiY0"
      },
      "source": [
        "#Generując losowy zbiór danych odpowiadający pod względem rozmiarów zbioru użytego do budowy modelu możemy uzyskać punkt odniesienia względem uzyskanych wyników oraz sprawdzić jakość danych\n",
        "import random\n",
        "X_rand = pd.DataFrame(np.random.randint(0,100, size=X.shape), columns=X.columns)\n",
        "\n",
        "regLin_rand = linear_model.LinearRegression()\n",
        "regLin_rand.fit(X_rand, Y)\n",
        "y_pred = regLin_rand.predict(X_rand)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyesncQEqlYM",
        "outputId": "42abfb00-ee3a-4038-d37e-e474b40d201a"
      },
      "source": [
        "summary=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary[\"Observed\"]=Y.values\n",
        "summary\n",
        "RMSE=((summary['Observed']-summary['Predicted']).pow(2).sum()/len(summary['Predicted']))**0.5\n",
        "RMSE"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.372291686181104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKfo7VMxucRe"
      },
      "source": [
        "#Przygotujmy własną funkcję do oceny naszych modeli. Uwzględnimy bład RMSE, NRMSE oraz wsp. determinacji R2\n",
        "def modelResults (metric_type, observed, predicted):\n",
        "  r2=metrics.r2_score(observed, predicted)\n",
        "  rmse=metrics.mean_squared_error(observed, predicted, squared=False)\n",
        "  nrmse=100*rmse/(observed.values.max()-observed.values.min())\n",
        "  print(metric_type)\n",
        "  print('R2:', r2)\n",
        "  print(\"RMSE:\", rmse)\n",
        "  print(\"NRMSE: %.2f %%\" %nrmse)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOtMcPfpvonN",
        "outputId": "6dd25191-51db-4464-eda0-e6c8c206234c"
      },
      "source": [
        "#Wyniki dla modelu danymi losowymi - R2 wskazuje na brak zależności Observed(Predicted) a wartość RMSE nie wygląda \"źle\" :)\n",
        "modelResults(\"LearnError\", summary['Observed'], summary['Predicted'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LearnError\n",
            "R2: 0.0025120488789420747\n",
            "RMSE: 2.372291686181104\n",
            "NRMSE: 15.50 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwcAzlmDwHum",
        "outputId": "63ec5fcd-5e6f-4892-9320-2ff150374fe7"
      },
      "source": [
        "#Jeszcze nasz model regresji liniowej dla porównania - model wyjaśnia ponad 50% zmienności w zbiorze \n",
        "y_pred=regLin.predict(X)\n",
        "summary_reglin=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary_reglin[\"Observed\"]=Y.values\n",
        "summary_reglin\n",
        "modelResults(\"LearnError\", summary_reglin['Observed'], summary_reglin['Predicted'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LearnError\n",
            "R2: 0.5180140767210677\n",
            "RMSE: 1.649040928952181\n",
            "NRMSE: 10.77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLwlgNW6vU9D"
      },
      "source": [
        "# Modyfikacje modelu w zakresie wektora wejściowego"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxORfC1awuux",
        "outputId": "20aba86f-d626-4c7f-e935-80e0fee1fd31"
      },
      "source": [
        "#Sprawdźmy jakie mamy zmienne wejściowe\n",
        "X.columns"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MolWt', 'MolLogP', 'MolMR', 'HeavyAtomCount', 'NumHAcceptors',\n",
              "       'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds',\n",
              "       'NumValenceElectrons', 'NumAromaticRings', 'NumSaturatedRings',\n",
              "       'NumAliphaticRings', 'RingCount', 'TPSA', 'LabuteASA', 'BalabanJ',\n",
              "       'BertzCT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EbymDubw3_Q",
        "outputId": "71eabb00-ef89-442d-c538-d997147254a2"
      },
      "source": [
        "#Wybierzmy kilka i zbudujmy model, którego struktura będzie uproszczona względem pierwszego modelu, takie uproszczenia mogą być tworzone w sposób systematyczny lub losowy.\n",
        "X_simpl=X[['BalabanJ', 'MolLogP', 'HeavyAtomCount']]\n",
        "\n",
        "regLin_simpl = linear_model.LinearRegression()\n",
        "regLin_simpl.fit(X_simpl, Y)\n",
        "y_pred = regLin_simpl.predict(X_simpl)\n",
        "\n",
        "summary_simpl=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary_simpl[\"Observed\"]=Y.values\n",
        "modelResults(\"LearnError\", summary_simpl['Observed'], summary_simpl['Predicted'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LearnError\n",
            "R2: 0.41025650070958997\n",
            "RMSE: 1.824088220592901\n",
            "NRMSE: 11.91 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGOzpR-Jv9Q7"
      },
      "source": [
        "# Regresja Lasso i regularyzacja L1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwzQbrpGyUJC",
        "outputId": "43b13474-007b-4fb2-d4c1-ae8aca57a27d"
      },
      "source": [
        "#Tworzymy model oraz testujemy go. Warto zmodyfikować wsp. alpha i sprawdzić wpływ regularyzacji na strukturę oraz błąd modelu\n",
        "reg_lasso=linear_model.Lasso(alpha=0.03)\n",
        "reg_lasso.fit(X, Y)\n",
        "y_pred = reg_lasso.predict(X)\n",
        "summary_lasso=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary_lasso[\"Observed\"]=Y.values\n",
        "modelResults(\"LearnError\", summary_lasso['Observed'], summary_lasso['Predicted'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LearnError\n",
            "R2: 0.5150670890814805\n",
            "RMSE: 1.6540745795737848\n",
            "NRMSE: 10.80 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2660.931317987892, tolerance: 5.575365775106009\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "nm5Uf8m0zBWh",
        "outputId": "914f45be-99d1-4013-a7be-a77f92ea016f"
      },
      "source": [
        "#Struktura modelu - niektóre parametry mają wartość 0 co jest wzkazaniem o ich wykluczeniu w procesie uczenia z uwagi na niewielki wpływ na wartości przewidywane względem wartości wag (współczynnika)\n",
        "coeff_imp=pd.DataFrame(reg_lasso.coef_, index=X.columns, columns=[\"lasso_coef\"])\n",
        "coeff_imp"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lasso_coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MolWt</th>\n",
              "      <td>-0.004728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolLogP</th>\n",
              "      <td>-0.445606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolMR</th>\n",
              "      <td>0.013314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <td>-0.317371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <td>0.073243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHDonors</th>\n",
              "      <td>0.117048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <td>-0.092678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <td>0.048828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <td>0.057046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <td>-0.324994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RingCount</th>\n",
              "      <td>-0.233734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TPSA</th>\n",
              "      <td>-0.002401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabuteASA</th>\n",
              "      <td>-0.015042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BalabanJ</th>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BertzCT</th>\n",
              "      <td>0.003579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     lasso_coef\n",
              "MolWt                 -0.004728\n",
              "MolLogP               -0.445606\n",
              "MolMR                  0.013314\n",
              "HeavyAtomCount        -0.317371\n",
              "NumHAcceptors          0.073243\n",
              "NumHDonors             0.117048\n",
              "NumHeteroatoms        -0.092678\n",
              "NumRotatableBonds      0.048828\n",
              "NumValenceElectrons    0.057046\n",
              "NumAromaticRings      -0.324994\n",
              "NumSaturatedRings      0.000000\n",
              "NumAliphaticRings      0.000000\n",
              "RingCount             -0.233734\n",
              "TPSA                  -0.002401\n",
              "LabuteASA             -0.015042\n",
              "BalabanJ              -0.000000\n",
              "BertzCT                0.003579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWCIVc-gwqGf"
      },
      "source": [
        "# Uczenie oraz testowanie modelu - rozterka wyboru modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74LLNRJ0XDY"
      },
      "source": [
        "#Podział zmiennych wejściowych i wyjściowych na część uczacą oraz testową\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=1, shuffle=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLB_nwh91dCo",
        "outputId": "568b5a66-795e-4c0c-e1dd-641276a287fa"
      },
      "source": [
        "#Do wyboru modelu uzywamy błędu uzyskanego na danych testowych\n",
        "reg_lasso2=linear_model.Lasso(alpha=0.01, max_iter=10000)\n",
        "reg_lasso2.fit(X_train, y_train)\n",
        "y_pred = reg_lasso2.predict(X_test)\n",
        "y_learn = reg_lasso2.predict(X_train)\n",
        "\n",
        "summary_lasso2_learn=pd.DataFrame(y_learn, columns=[\"Predicted\"])\n",
        "summary_lasso2_learn[\"Observed\"]=y_train.reset_index(drop=True)\n",
        "\n",
        "summary_lasso2_test=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary_lasso2_test[\"Observed\"]=y_test.reset_index(drop=True)\n",
        "\n",
        "modelResults(\"LernError\", summary_lasso2_learn['Observed'], summary_lasso2_learn['Predicted'])\n",
        "modelResults(\"TestError\", summary_lasso2_test['Observed'], summary_lasso2_test['Predicted'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LernError\n",
            "R2: 0.5340266177152977\n",
            "RMSE: 1.630784383582548\n",
            "NRMSE: 10.65 %\n",
            "TestError\n",
            "R2: 0.4226619606775399\n",
            "RMSE: 1.7622036942911765\n",
            "NRMSE: 12.98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrKuid1Pqom9"
      },
      "source": [
        "# Koncepcja k-krotnej wazjemnego sprawdzania (k-fold cross-validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqoZRY0axoR7"
      },
      "source": [
        "Powyższy kod uruchomony kilkukrotnie wygeneruje wartości różniące się od siebie. Im mniejszy zbiór danych tym ta zmienność jest większa. K-krotna coss-walidacja pozwala na wyniki char. się większą stabilnością oraz jednocześnie pozwala na testowanie modelu na wszystkich dostępnych przypadkach dostarczając większej ilości informacji o jego jakości. Dane dzielone są na k-częsci a następnie każda część niezależnie stanowi zbiór testowy a komplementarne częsci zbiór uczący. Najczęściej jako k przyjmuje się 10.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hml22k2Sq7sm"
      },
      "source": [
        "#Tworzymy objekt odpowiedzialny za proces k-cv, model regresji lasso\n",
        "cv = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "reg_lasso3=linear_model.Lasso(alpha=0.01, max_iter=10000)\n",
        "scores = model_selection.cross_validate(reg_lasso3, X=X, y=Y, cv=cv, scoring=['neg_root_mean_squared_error', 'r2'], return_train_score=True, return_estimator=True)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "gQvFn9zPyip9",
        "outputId": "8ef78b54-c167-4df9-b726-1d4ac3f40cbd"
      },
      "source": [
        "#Każdy z 10 modeli może być zastosowany oraz poddany analizie\n",
        "scores['estimator'][0].predict(X)\n",
        "coeff_imp=pd.DataFrame(scores['estimator'][0].coef_, index=X.columns, columns=[\"lasso_coef\"])\n",
        "coeff_imp"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lasso_coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MolWt</th>\n",
              "      <td>-0.004954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolLogP</th>\n",
              "      <td>-0.454948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolMR</th>\n",
              "      <td>0.015266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <td>-0.432658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <td>0.093454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHDonors</th>\n",
              "      <td>0.133413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <td>-0.113956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <td>0.043589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <td>0.073009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <td>-0.310603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <td>0.047557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RingCount</th>\n",
              "      <td>-0.310138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TPSA</th>\n",
              "      <td>-0.003533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabuteASA</th>\n",
              "      <td>-0.012688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BalabanJ</th>\n",
              "      <td>-0.010408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BertzCT</th>\n",
              "      <td>0.004252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     lasso_coef\n",
              "MolWt                 -0.004954\n",
              "MolLogP               -0.454948\n",
              "MolMR                  0.015266\n",
              "HeavyAtomCount        -0.432658\n",
              "NumHAcceptors          0.093454\n",
              "NumHDonors             0.133413\n",
              "NumHeteroatoms        -0.113956\n",
              "NumRotatableBonds      0.043589\n",
              "NumValenceElectrons    0.073009\n",
              "NumAromaticRings      -0.310603\n",
              "NumSaturatedRings      0.047557\n",
              "NumAliphaticRings      0.000000\n",
              "RingCount             -0.310138\n",
              "TPSA                  -0.003533\n",
              "LabuteASA             -0.012688\n",
              "BalabanJ              -0.010408\n",
              "BertzCT                0.004252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eWrTbs5zX5J",
        "outputId": "aab0b2f0-6a77-452f-997c-a0700d7a7862"
      },
      "source": [
        "#Podsumujmy wyniki uczenia i testowania\n",
        "print(\"Test mean RMSE:\", -scores['test_neg_root_mean_squared_error'].mean())\n",
        "print(\"Test mean R2:\", scores['test_r2'].mean())\n",
        "print(\"Test mean RMSE:\", -scores['test_neg_root_mean_squared_error'].mean())\n",
        "print(\"Test mean R2:\", scores['test_r2'].mean())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test mean RMSE: 1.6728643436898327\n",
            "Test mean R2: 0.5010798819430954\n",
            "Test mean RMSE: 1.6728643436898327\n",
            "Test mean R2: 0.5010798819430954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycwxnnMt6hhj"
      },
      "source": [
        "# Regresja Ridge i regularyzacja L2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mq8SzIQ6qbX",
        "outputId": "b54698a3-168b-415c-e5f7-2fc7aa03e5e8"
      },
      "source": [
        "#Podział zmiennych wejściowych i wyjściowych na część uczacą oraz testową\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=1, shuffle=True)\n",
        "\n",
        "#Model regresji Ridge\n",
        "reg_ridge=linear_model.Ridge(alpha=0.1, max_iter=10000)\n",
        "reg_ridge.fit(X_train, y_train)\n",
        "y_pred = reg_ridge.predict(X_test)\n",
        "y_learn = reg_ridge.predict(X_train)\n",
        "\n",
        "#Podsumowanie wyników\n",
        "summary_ridge_learn2=pd.DataFrame(y_learn, columns=[\"Predicted\"])\n",
        "summary_ridge_learn2[\"Observed\"]=y_train.reset_index(drop=True)\n",
        "\n",
        "summary_ridge_test2=pd.DataFrame(y_pred, columns=[\"Predicted\"])\n",
        "summary_ridge_test2[\"Observed\"]=y_test.reset_index(drop=True)\n",
        "\n",
        "modelResults(\"LernError\", summary_ridge_learn2['Observed'], summary_ridge_learn2['Predicted'])\n",
        "modelResults(\"TestError\", summary_ridge_test2['Observed'], summary_ridge_test2['Predicted'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LernError\n",
            "R2: 0.534417745909036\n",
            "RMSE: 1.630099816953485\n",
            "NRMSE: 10.65 %\n",
            "TestError\n",
            "R2: 0.42193455214663766\n",
            "RMSE: 1.7633134760895512\n",
            "NRMSE: 12.98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNhrI0j370Me",
        "outputId": "7bee51eb-3a5b-4562-ba32-eafcf4e5b737"
      },
      "source": [
        "#Struktura modelu\n",
        "reg_ridge.coef_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00843026, -0.45873937,  0.01798606, -0.49178576,  0.09129928,\n",
              "        0.14853301, -0.08371809,  0.02954703,  0.08465153, -0.28430044,\n",
              "        0.19586523, -0.08410234, -0.36840279, -0.00523246, -0.00932468,\n",
              "       -0.06010817,  0.00463928])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoYXTUnN6fl5",
        "outputId": "c50f8b39-4a31-419a-f060-226ab1bc0be1"
      },
      "source": [
        "#Metoda 10-CV\n",
        "cv = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "reg_ridge2=linear_model.Ridge(alpha=0.2, max_iter=10000)\n",
        "scores_ridge = model_selection.cross_validate(reg_ridge2, X=X, y=Y, cv=cv, scoring=['neg_root_mean_squared_error', 'r2'], return_train_score=True, return_estimator=True)\n",
        "\n",
        "#Podsumujmy wyniki uczenia i testowania\n",
        "print(\"Learn mean RMSE:\", -scores_ridge['train_neg_root_mean_squared_error'].mean())\n",
        "print(\"Learn mean R2:\", scores_ridge['train_r2'].mean())\n",
        "print(\"Test mean RMSE:\", -scores_ridge['test_neg_root_mean_squared_error'].mean())\n",
        "print(\"Test mean R2:\", scores_ridge['test_r2'].mean())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn mean RMSE: 1.6478877293350878\n",
            "Learn mean R2: 0.518670965506707\n",
            "Test mean RMSE: 1.6720089140115104\n",
            "Test mean R2: 0.503156257105139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqIhZtUU86OD",
        "outputId": "6c2f80fc-a87b-4ee9-fb8a-8018c5a1676a"
      },
      "source": [
        "scores_ridge"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "  Ridge(alpha=0.2, copy_X=True, fit_intercept=True, max_iter=10000,\n",
              "        normalize=False, random_state=None, solver='auto', tol=0.001)),\n",
              " 'fit_time': array([0.0056181 , 0.00540423, 0.0050149 , 0.00553823, 0.00575304,\n",
              "        0.00550485, 0.00507164, 0.00534582, 0.00560474, 0.01080275]),\n",
              " 'score_time': array([0.00215197, 0.00256348, 0.00204372, 0.00218415, 0.00224662,\n",
              "        0.00213361, 0.00216985, 0.00213075, 0.00222898, 0.00229168]),\n",
              " 'test_neg_root_mean_squared_error': array([-1.74698566, -1.63414614, -1.61157214, -1.63075569, -1.63838638,\n",
              "        -1.66738083, -1.78692359, -1.69803563, -1.59049287, -1.71541021]),\n",
              " 'test_r2': array([0.45157393, 0.51057565, 0.5618556 , 0.50241614, 0.49566466,\n",
              "        0.53419476, 0.45634472, 0.50445065, 0.51191065, 0.50257581]),\n",
              " 'train_neg_root_mean_squared_error': array([-1.64002854, -1.65100745, -1.65363342, -1.65159019, -1.65068989,\n",
              "        -1.65071322, -1.63781276, -1.64531479, -1.65572648, -1.64236057]),\n",
              " 'train_r2': array([0.52397719, 0.51851554, 0.51258022, 0.51932973, 0.52004329,\n",
              "        0.51380766, 0.52226858, 0.51851273, 0.51837656, 0.51929816])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "yIelBOWVAAmR",
        "outputId": "4baad9ed-72a0-4b07-fd30-0c8012507233"
      },
      "source": [
        "#Struktura modelu\n",
        "pd.DataFrame(scores_ridge['estimator'][0].coef_, index=X.columns, columns=[\"Elastic coeff\"])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elastic coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MolWt</th>\n",
              "      <td>-0.004331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolLogP</th>\n",
              "      <td>-0.467162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolMR</th>\n",
              "      <td>0.016061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <td>-0.436821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <td>0.112515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHDonors</th>\n",
              "      <td>0.135576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <td>-0.120666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <td>0.025226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <td>0.073240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <td>-0.291432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <td>0.134007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <td>-0.058265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RingCount</th>\n",
              "      <td>-0.349698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TPSA</th>\n",
              "      <td>-0.003963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabuteASA</th>\n",
              "      <td>-0.013370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BalabanJ</th>\n",
              "      <td>-0.005684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BertzCT</th>\n",
              "      <td>0.004244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Elastic coeff\n",
              "MolWt                    -0.004331\n",
              "MolLogP                  -0.467162\n",
              "MolMR                     0.016061\n",
              "HeavyAtomCount           -0.436821\n",
              "NumHAcceptors             0.112515\n",
              "NumHDonors                0.135576\n",
              "NumHeteroatoms           -0.120666\n",
              "NumRotatableBonds         0.025226\n",
              "NumValenceElectrons       0.073240\n",
              "NumAromaticRings         -0.291432\n",
              "NumSaturatedRings         0.134007\n",
              "NumAliphaticRings        -0.058265\n",
              "RingCount                -0.349698\n",
              "TPSA                     -0.003963\n",
              "LabuteASA                -0.013370\n",
              "BalabanJ                 -0.005684\n",
              "BertzCT                   0.004244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mT6wUcr99Ph"
      },
      "source": [
        "# Sieci elastyczne - regularyzacja L1 i L2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsv35f4Z98ng",
        "outputId": "b5a06ef1-278b-4a79-fce4-21e608f4319e"
      },
      "source": [
        "#Metoda 10-CV\n",
        "cv = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "reg_elastic=linear_model.ElasticNet(alpha=0.2, l1_ratio=0.1, max_iter=10000)\n",
        "scores_elastic = model_selection.cross_validate(reg_elastic, X=X, y=Y, cv=cv, scoring=['neg_root_mean_squared_error', 'r2'], return_train_score=True, return_estimator=True)\n",
        "\n",
        "#Podsumujmy wyniki uczenia i testowania\n",
        "print(\"Learn mean RMSE:\", -scores_elastic['train_neg_root_mean_squared_error'].mean())\n",
        "print(\"Learn mean R2:\", scores_elastic['train_r2'].mean())\n",
        "print(\"Test mean RMSE:\", -scores_elastic['test_neg_root_mean_squared_error'].mean())\n",
        "print(\"Test mean R2:\", scores_elastic['test_r2'].mean())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn mean RMSE: 1.6590160405050203\n",
            "Learn mean R2: 0.5121307736384856\n",
            "Test mean RMSE: 1.6784083118420416\n",
            "Test mean R2: 0.497596194496289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "MK6QOvZY-4wh",
        "outputId": "0f022517-4ab4-4c6b-fff5-0575cf037e76"
      },
      "source": [
        "#Struktura modelu\n",
        "pd.DataFrame(scores_elastic['estimator'][0].coef_, index=X.columns, columns=[\"Elastic coeff\"])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elastic coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MolWt</th>\n",
              "      <td>-0.005145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolLogP</th>\n",
              "      <td>-0.419930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MolMR</th>\n",
              "      <td>0.008583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeavyAtomCount</th>\n",
              "      <td>-0.236940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <td>0.068987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHDonors</th>\n",
              "      <td>0.124655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumHeteroatoms</th>\n",
              "      <td>-0.054925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <td>0.067993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <td>0.043648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAromaticRings</th>\n",
              "      <td>-0.198137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSaturatedRings</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumAliphaticRings</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RingCount</th>\n",
              "      <td>-0.134937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TPSA</th>\n",
              "      <td>-0.002088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabuteASA</th>\n",
              "      <td>-0.011888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BalabanJ</th>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BertzCT</th>\n",
              "      <td>0.002401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Elastic coeff\n",
              "MolWt                    -0.005145\n",
              "MolLogP                  -0.419930\n",
              "MolMR                     0.008583\n",
              "HeavyAtomCount           -0.236940\n",
              "NumHAcceptors             0.068987\n",
              "NumHDonors                0.124655\n",
              "NumHeteroatoms           -0.054925\n",
              "NumRotatableBonds         0.067993\n",
              "NumValenceElectrons       0.043648\n",
              "NumAromaticRings         -0.198137\n",
              "NumSaturatedRings         0.000000\n",
              "NumAliphaticRings         0.000000\n",
              "RingCount                -0.134937\n",
              "TPSA                     -0.002088\n",
              "LabuteASA                -0.011888\n",
              "BalabanJ                 -0.000000\n",
              "BertzCT                   0.002401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm0oAih9AppT"
      },
      "source": [
        "# Tuning parametrów modelu - automatyzacja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGttGUVz_0Ja",
        "outputId": "ad221d38-5ebb-447f-cd72-2fca09b4f194"
      },
      "source": [
        "#Definiujey parametry które chcemy tuningować\n",
        "parameters = {'alpha': [0.01, 0.2, 0.5], 'l1_ratio': [0.1, 0.5, 0.7]}\n",
        "\n",
        "#Definiujemy objekt k-CV\n",
        "cv = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "#Definiujemy model\n",
        "reg_elastic=linear_model.ElasticNet(max_iter=10000)\n",
        "\n",
        "#W końcu tworzymy objekt odpowiedzialny za poszukiwanie optymalnych parametrów i arch.\n",
        "reg_elastic_gs = model_selection.GridSearchCV(reg_elastic, parameters, cv=cv, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "#Uczymy i testujemy rozwiązania\n",
        "reg_elastic_gs.fit(X,Y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                                  l1_ratio=0.5, max_iter=10000, normalize=False,\n",
              "                                  positive=False, precompute=False,\n",
              "                                  random_state=None, selection='cyclic',\n",
              "                                  tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.01, 0.2, 0.5],\n",
              "                         'l1_ratio': [0.1, 0.5, 0.7]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_root_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJwIyQIeJnzk",
        "outputId": "5dc3682d-8bbd-4120-9a2f-e7ee5914970e"
      },
      "source": [
        "#Spwardźmy najlepszy model\n",
        "reg_elastic_gs.best_estimator_"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
              "           max_iter=10000, normalize=False, positive=False, precompute=False,\n",
              "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmSz5nhmMjn7",
        "outputId": "b66282e5-42e4-4e5d-c58e-7c0dd39b77b3"
      },
      "source": [
        "#Uczymy i testujemy najlepszy model zgodnie z przyjętą metodyką\n",
        "reg_elastic=linear_model.ElasticNet(alpha=0.01, l1_ratio=0.1, max_iter=10000)\n",
        "scores_elastic = model_selection.cross_validate(reg_elastic, X=X, y=Y, cv=cv, scoring=['neg_root_mean_squared_error', 'r2'], return_train_score=True, return_estimator=True)\n",
        "\n",
        "#Podsumujmy wyniki uczenia i testowania\n",
        "print(\"Learn mean RMSE:\", -scores_elastic['train_neg_root_mean_squared_error'].mean())\n",
        "print(\"Learn mean R2:\", scores_elastic['train_r2'].mean())\n",
        "print(\"Test mean RMSE:\", -scores_elastic['test_neg_root_mean_squared_error'].mean())\n",
        "print(\"Test mean R2:\", scores_elastic['test_r2'].mean())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learn mean RMSE: 1.648214882510127\n",
            "Learn mean R2: 0.5184683399998768\n",
            "Test mean RMSE: 1.6654665305844305\n",
            "Test mean R2: 0.5059211208416861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeJ141BxAGgY"
      },
      "source": [
        "# Sztuczne sieci neuronowe (ANN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvgxGApRLCB"
      },
      "source": [
        "#Podział na pliki uczące i testowe\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "                                    X, Y, test_size=0.20, random_state=42, shuffle=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzN_dYwiRTpa"
      },
      "source": [
        "#Skalowanie danych wejściowych i wyjściowych\n",
        "scalerX=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerX.fit(X_train)\n",
        "X_train_scaled=scalerX.transform(X_train)\n",
        "X_test_scaled=scalerX.transform(X_test)\n",
        "\n",
        "scalerY=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerY.fit(y_train.values.reshape(-1,1))\n",
        "y_train_scaled=scalerY.transform(y_train.values.reshape(-1,1))\n",
        "y_test_scaled=scalerY.transform(y_test.values.reshape(-1,1))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ChtMSwpySiVf",
        "outputId": "a709ff65-6ecb-47b7-f77f-a372bc85ee9e"
      },
      "source": [
        "#Tworzymy sieć neuronową - prosze zobaczyć jakie parametry możemy modyfikować - optymalizować/tuningować\n",
        "mlp=neural_network.MLPRegressor(hidden_layer_sizes=(100, 50, 30), activation='relu', solver='lbfgs',\n",
        "                            max_iter=1000)\n",
        "\n",
        "#Uczymy model\n",
        "mlp.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "#Pamiętajmy, że po wykonaniu predykcji dane musimy ponownie skalować w celu obliczenia rzeczywistych wartości przewidywanych przez model: scaler*.inverse_transform\n",
        "y_pred = scalerY.inverse_transform(mlp.predict(X_test_scaled).reshape(-1,1))\n",
        "y_pred_train = scalerY.inverse_transform(mlp.predict(X_train_scaled).reshape(-1,1))\n",
        "\n",
        "plt.scatter(y=y_test, x=y_pred,  color='gray')\n",
        "plt.show()\n",
        "\n",
        "modelResults(\"Learn metrics\", y_train, y_pred_train)\n",
        "modelResults(\"Test metrics\", y_test, y_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Learn metrics\n",
            "R2: 0.8114180674653436\n",
            "RMSE: 1.0254788949518887\n",
            "NRMSE: 6.70 %\n",
            "Test metrics\n",
            "R2: 0.7768181721853182\n",
            "RMSE: 1.147692576121472\n",
            "NRMSE: 8.89 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rpv1SprT98j"
      },
      "source": [
        "# Zapisywanie i wczytywanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH45w7QHSMhL"
      },
      "source": [
        "#Zapiszmy nasz model na przyszłość używając pakietu pickle\n",
        "import pickle\n",
        "\n",
        "pickle.dump(mlp, open(\"MLP.mod\", 'wb'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybm5MKvcT9tX"
      },
      "source": [
        "#Wczytywanie modelu\n",
        "model = pickle.load(open(\"MLP.mod\", 'rb'))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNOP65bbU2bQ"
      },
      "source": [
        "# I koło się zamyka"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf0k5PL0U8hi"
      },
      "source": [
        "#Wczytajmy większy zbiór danych i zastosujmy tzw. sieci głębokie (DNN)\n",
        "df_full = pd.read_csv(\"https://raw.githubusercontent.com/adamPaclawski/AGH_DataScience_2021/master/Model_development_part1/extended_solubility.csv\", index_col=0)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5e68L1LVHU7"
      },
      "source": [
        "Y=df_full['logS']\n",
        "df_full.drop(labels=['logS'], axis=1, inplace=True)\n",
        "\n",
        "correlated_features = set()\n",
        "correlation_matrix=df_full.corr()\n",
        "\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
        "            colname = correlation_matrix.columns[i]\n",
        "            correlated_features.add(colname)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx-WGPKbVmdT"
      },
      "source": [
        "nocorr_df_full=df_full.drop(labels=correlated_features, axis=1, inplace=False)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "VVr_gfE5VszT",
        "outputId": "f0c67ba9-b328-42f5-e6d7-f2e59e395432"
      },
      "source": [
        "#Przygotujemy model regresji liniowej\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "                                    nocorr_df_full, Y, test_size=0.20, random_state=42, shuffle=True)\n",
        "\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "y_learn_pred = reg.predict(X_train)\n",
        "\n",
        "plt.scatter(y=y_test, x=y_pred,  color='gray')\n",
        "plt.show()\n",
        "\n",
        "modelResults(\"Learn metrics\", y_train, y_learn_pred)\n",
        "modelResults(\"Test metrics\", y_test, y_pred)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Learn metrics\n",
            "R2: 0.7387305931036834\n",
            "RMSE: 1.207038062973662\n",
            "NRMSE: 7.88 %\n",
            "Test metrics\n",
            "R2: 0.705794647823676\n",
            "RMSE: 1.3177148551600075\n",
            "NRMSE: 10.20 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "DtnqYKg-V6ck",
        "outputId": "8c09e2b0-584c-444c-c04e-44b15590c10e"
      },
      "source": [
        "#Model sieci neuronowej\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "                                    nocorr_df_full, Y, test_size=0.20, random_state=42, shuffle=True)\n",
        "\n",
        "scalerX=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerX.fit(X_train)\n",
        "X_train_scaled=scalerX.transform(X_train)\n",
        "X_test_scaled=scalerX.transform(X_test)\n",
        "\n",
        "scalerY=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerY.fit(y_train.values.reshape(-1,1))\n",
        "y_train_scaled=scalerY.transform(y_train.values.reshape(-1,1))\n",
        "y_test_scaled=scalerY.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "#Tworzymy sieć neuronową - prosze zobaczyć jakie parametry możemy modyfikować - optymalizować/tuningować\n",
        "mlp=neural_network.MLPRegressor(hidden_layer_sizes=(100, 50, 30), activation='relu', solver='lbfgs',\n",
        "                            max_iter=10000)\n",
        "\n",
        "#Uczymy model\n",
        "mlp.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "#Pamiętajmy, że po wykonaniu predykcji dane musimy ponownie skalować w celu obliczenia rzeczywistych wartości przewidywanych przez model: scaler*.inverse_transform\n",
        "y_pred = scalerY.inverse_transform(mlp.predict(X_test_scaled).reshape(-1,1))\n",
        "y_pred_train = scalerY.inverse_transform(mlp.predict(X_train_scaled).reshape(-1,1))\n",
        "\n",
        "plt.scatter(y=y_test, x=y_pred,  color='gray')\n",
        "plt.show()\n",
        "\n",
        "modelResults(\"Learn metrics\", y_train, y_pred_train)\n",
        "modelResults(\"Test metrics\", y_test, y_pred)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Learn metrics\n",
            "R2: 0.8572068003728283\n",
            "RMSE: 0.8923401792059458\n",
            "NRMSE: 5.83 %\n",
            "Test metrics\n",
            "R2: 0.7924431508198124\n",
            "RMSE: 1.1067886376755778\n",
            "NRMSE: 8.57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4kLNHpXGHi"
      },
      "source": [
        "# Sieci głębokie (DNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo2jvzjHW8dk",
        "outputId": "154ad376-1d13-4207-d152-af6ed2a41b20"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "                                    nocorr_df_full, Y, test_size=0.20, random_state=42, shuffle=True)\n",
        "\n",
        "scalerX=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerX.fit(X_train)\n",
        "X_train_scaled=scalerX.transform(X_train)\n",
        "X_test_scaled=scalerX.transform(X_test)\n",
        "\n",
        "scalerY=preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "scalerY.fit(y_train.values.reshape(-1,1))\n",
        "y_train_scaled=scalerY.transform(y_train.values.reshape(-1,1))\n",
        "y_test_scaled=scalerY.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "model.fit(X_train_scaled, y_train_scaled, epochs=1000, batch_size=500)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "16/16 [==============================] - 7s 9ms/step - loss: 0.2512 - mean_squared_error: 0.3178\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1042 - mean_squared_error: 0.1663\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0813 - mean_squared_error: 0.1333\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0653 - mean_squared_error: 0.1144\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0561 - mean_squared_error: 0.1018\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0466 - mean_squared_error: 0.0923\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0418 - mean_squared_error: 0.0846\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0382 - mean_squared_error: 0.0785\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0348 - mean_squared_error: 0.0734\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0328 - mean_squared_error: 0.0691\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0313 - mean_squared_error: 0.0656\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0309 - mean_squared_error: 0.0625\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0311 - mean_squared_error: 0.0599\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0277 - mean_squared_error: 0.0576\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0289 - mean_squared_error: 0.0556\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0280 - mean_squared_error: 0.0538\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0257 - mean_squared_error: 0.0521\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0263 - mean_squared_error: 0.0506\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0257 - mean_squared_error: 0.0492\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0249 - mean_squared_error: 0.0480\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0242 - mean_squared_error: 0.0468\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0237 - mean_squared_error: 0.0458\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0231 - mean_squared_error: 0.0448\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0219 - mean_squared_error: 0.0438\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0222 - mean_squared_error: 0.0429\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0216 - mean_squared_error: 0.0421\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0211 - mean_squared_error: 0.0413\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0214 - mean_squared_error: 0.0406\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0206 - mean_squared_error: 0.0398\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0202 - mean_squared_error: 0.0392\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0190 - mean_squared_error: 0.0385\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0188 - mean_squared_error: 0.0379\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0180 - mean_squared_error: 0.0373\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0179 - mean_squared_error: 0.0367\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0178 - mean_squared_error: 0.0362\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0169 - mean_squared_error: 0.0356\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0171 - mean_squared_error: 0.0351\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0161 - mean_squared_error: 0.0346\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0164 - mean_squared_error: 0.0341\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0158 - mean_squared_error: 0.0337\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0155 - mean_squared_error: 0.0332\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0146 - mean_squared_error: 0.0328\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0149 - mean_squared_error: 0.0324\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0143 - mean_squared_error: 0.0320\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0145 - mean_squared_error: 0.0316\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0145 - mean_squared_error: 0.0312\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0133 - mean_squared_error: 0.0308\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0140 - mean_squared_error: 0.0305\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0132 - mean_squared_error: 0.0301\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0128 - mean_squared_error: 0.0298\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0123 - mean_squared_error: 0.0294\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0126 - mean_squared_error: 0.0291\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0123 - mean_squared_error: 0.0288\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0120 - mean_squared_error: 0.0285\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0122 - mean_squared_error: 0.0282\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0117 - mean_squared_error: 0.0279\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0118 - mean_squared_error: 0.0276\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0118 - mean_squared_error: 0.0273\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0112 - mean_squared_error: 0.0270\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0109 - mean_squared_error: 0.0268\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0110 - mean_squared_error: 0.0265\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0107 - mean_squared_error: 0.0262\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0107 - mean_squared_error: 0.0260\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0100 - mean_squared_error: 0.0257\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0104 - mean_squared_error: 0.0255\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0096 - mean_squared_error: 0.0253\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0102 - mean_squared_error: 0.0250\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0098 - mean_squared_error: 0.0248\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0097 - mean_squared_error: 0.0246\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0095 - mean_squared_error: 0.0244\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0094 - mean_squared_error: 0.0242\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0095 - mean_squared_error: 0.0240\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0091 - mean_squared_error: 0.0238\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0094 - mean_squared_error: 0.0236\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0091 - mean_squared_error: 0.0234\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0091 - mean_squared_error: 0.0232\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0091 - mean_squared_error: 0.0230\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0090 - mean_squared_error: 0.0228\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0092 - mean_squared_error: 0.0226\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0085 - mean_squared_error: 0.0225\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0088 - mean_squared_error: 0.0223\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0088 - mean_squared_error: 0.0221\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0088 - mean_squared_error: 0.0220\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0088 - mean_squared_error: 0.0218\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0086 - mean_squared_error: 0.0217\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0083 - mean_squared_error: 0.0215\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0085 - mean_squared_error: 0.0213\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0083 - mean_squared_error: 0.0212\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0084 - mean_squared_error: 0.0211\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_error: 0.0209\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_error: 0.0208\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0081 - mean_squared_error: 0.0206\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0081 - mean_squared_error: 0.0205\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0083 - mean_squared_error: 0.0204\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0081 - mean_squared_error: 0.0202\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0080 - mean_squared_error: 0.0201\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0079 - mean_squared_error: 0.0200\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0079 - mean_squared_error: 0.0199\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0197\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0079 - mean_squared_error: 0.0196\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_error: 0.0195\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0077 - mean_squared_error: 0.0194\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0193\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0192\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0078 - mean_squared_error: 0.0191\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0190\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0077 - mean_squared_error: 0.0188\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0081 - mean_squared_error: 0.0187\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0186\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0075 - mean_squared_error: 0.0185\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0184\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0078 - mean_squared_error: 0.0183\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0183\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0182\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0181\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0180\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0179\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0075 - mean_squared_error: 0.0178\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0075 - mean_squared_error: 0.0177\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_squared_error: 0.0176\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0175\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0075 - mean_squared_error: 0.0175\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_squared_error: 0.0174\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0173\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0077 - mean_squared_error: 0.0172\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0172\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0171\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0170\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0077 - mean_squared_error: 0.0169\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0077 - mean_squared_error: 0.0169\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0168\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_squared_error: 0.0167\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0166\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0075 - mean_squared_error: 0.0166\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0074 - mean_squared_error: 0.0165\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0164\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0076 - mean_squared_error: 0.0164\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0163\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0162\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_squared_error: 0.0162\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0071 - mean_squared_error: 0.0161\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0160\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0073 - mean_squared_error: 0.0160\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0071 - mean_squared_error: 0.0159\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_squared_error: 0.0159\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0158\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0157\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0157\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0156\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0156\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0073 - mean_squared_error: 0.0155\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0072 - mean_squared_error: 0.0155\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0075 - mean_squared_error: 0.0154\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0072 - mean_squared_error: 0.0154\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0072 - mean_squared_error: 0.0153\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0153\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_error: 0.0152\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0074 - mean_squared_error: 0.0151\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0073 - mean_squared_error: 0.0151\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0071 - mean_squared_error: 0.0150\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0150\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0071 - mean_squared_error: 0.0149\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0149\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0149\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0072 - mean_squared_error: 0.0148\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0148\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0147\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_squared_error: 0.0147\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0068 - mean_squared_error: 0.0146\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0146\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0145\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_error: 0.0145\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0144\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_squared_error: 0.0144\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0144\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0143\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0143\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_squared_error: 0.0142\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0142\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0068 - mean_squared_error: 0.0142\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0071 - mean_squared_error: 0.0141\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_squared_error: 0.0141\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0140\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0140\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0140\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0139\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0072 - mean_squared_error: 0.0139\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0138\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0138\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0068 - mean_squared_error: 0.0138\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0137\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0137\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_squared_error: 0.0137\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_error: 0.0136\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0070 - mean_squared_error: 0.0136\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_squared_error: 0.0136\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - mean_squared_error: 0.0135\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0135\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0135\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0134\n",
            "Epoch 201/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0134\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0134\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_squared_error: 0.0133\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_error: 0.0133\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0133\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0132\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0065 - mean_squared_error: 0.0132\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0132\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0131\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0131\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0131\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0130\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0130\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0130\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0129\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_squared_error: 0.0129\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0129\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0071 - mean_squared_error: 0.0129\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_error: 0.0128\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0128\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0128\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0128\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0127\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0068 - mean_squared_error: 0.0127\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0127\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0126\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0126\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0126\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0126\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0125\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0125\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_squared_error: 0.0125\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0125\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0124\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0068 - mean_squared_error: 0.0124\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0124\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0124\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0123\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0123\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0123\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0065 - mean_squared_error: 0.0123\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0122\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0122\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_squared_error: 0.0122\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0122\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0121\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0121\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0121\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0121\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0121\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_squared_error: 0.0120\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0120\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0120\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0120\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0119\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0119\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0119\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0119\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0119\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0118\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_error: 0.0118\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0118\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_squared_error: 0.0118\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0118\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0117\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0117\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0117\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0117\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0065 - mean_squared_error: 0.0117\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0116\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0116\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0116\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0116\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0116\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0115\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0115\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0065 - mean_squared_error: 0.0115\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0115\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0115\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0114\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0114\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0114\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0114\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0114\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0114\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0113\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0113\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0113\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0113\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0113\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0113\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0112\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0112\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0060 - mean_squared_error: 0.0112\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0112\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0112\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0112\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0111\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0111\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0111\n",
            "Epoch 301/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0111\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - mean_squared_error: 0.0111\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0111\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0110\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0110\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0110\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0110\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0110\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0110\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0109\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_error: 0.0109\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_error: 0.0109\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0109\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0109\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0109\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_error: 0.0109\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_squared_error: 0.0108\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0108\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0108\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_squared_error: 0.0108\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_error: 0.0108\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0108\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0060 - mean_squared_error: 0.0108\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0107\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0107\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0107\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0107\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0107\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0066 - mean_squared_error: 0.0107\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0107\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0106\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0064 - mean_squared_error: 0.0106\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0106\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0065 - mean_squared_error: 0.0106\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0064 - mean_squared_error: 0.0106\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0106\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0106\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0106\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0105\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0105\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0105\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0105\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0105\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0105\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0105\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0104\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - mean_squared_error: 0.0104\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0104\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0104\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0104\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0104\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0104\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0104\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0103\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0103\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0103\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0103\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0103\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0103\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0103\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0103\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0103\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0102\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0102\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0102\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0102\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0102\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0063 - mean_squared_error: 0.0102\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0102\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0102\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0102\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_squared_error: 0.0101\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_squared_error: 0.0101\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0101\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0101\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0101\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0101\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0101\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0101\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0101\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0100\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0100\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0100\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0100\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0100\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0100\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_error: 0.0100\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0058 - mean_squared_error: 0.0100\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0100\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0100\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0099\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0099\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0099\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0099\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0099\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0099\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0099\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0099\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0099\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0099\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0098\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_squared_error: 0.0098\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0098\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0098\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0098\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0098\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0098\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0098\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0098\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0098\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0098\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0097\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0063 - mean_squared_error: 0.0097\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0097\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0097\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0097\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0097\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0097\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0097\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0097\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0097\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0097\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0096\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0096\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0096\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0096\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0096\n",
            "Epoch 428/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0096\n",
            "Epoch 429/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0096\n",
            "Epoch 430/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0060 - mean_squared_error: 0.0096\n",
            "Epoch 431/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0096\n",
            "Epoch 432/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0096\n",
            "Epoch 433/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0096\n",
            "Epoch 434/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0096\n",
            "Epoch 435/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0095\n",
            "Epoch 436/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0095\n",
            "Epoch 437/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0095\n",
            "Epoch 438/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0095\n",
            "Epoch 439/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0095\n",
            "Epoch 440/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - mean_squared_error: 0.0095\n",
            "Epoch 441/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0095\n",
            "Epoch 442/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0095\n",
            "Epoch 443/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0095\n",
            "Epoch 444/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0095\n",
            "Epoch 445/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0095\n",
            "Epoch 446/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0095\n",
            "Epoch 447/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0094\n",
            "Epoch 448/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0094\n",
            "Epoch 449/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0094\n",
            "Epoch 450/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0094\n",
            "Epoch 451/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0094\n",
            "Epoch 452/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_squared_error: 0.0094\n",
            "Epoch 453/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0094\n",
            "Epoch 454/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0094\n",
            "Epoch 455/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0094\n",
            "Epoch 456/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0094\n",
            "Epoch 457/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0094\n",
            "Epoch 458/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0094\n",
            "Epoch 459/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0094\n",
            "Epoch 460/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0093\n",
            "Epoch 461/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_squared_error: 0.0093\n",
            "Epoch 462/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0093\n",
            "Epoch 463/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0093\n",
            "Epoch 464/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0093\n",
            "Epoch 465/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0093\n",
            "Epoch 466/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0093\n",
            "Epoch 467/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0093\n",
            "Epoch 468/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0093\n",
            "Epoch 469/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0093\n",
            "Epoch 470/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0093\n",
            "Epoch 471/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0093\n",
            "Epoch 472/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0093\n",
            "Epoch 473/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0093\n",
            "Epoch 474/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0092\n",
            "Epoch 475/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0092\n",
            "Epoch 476/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0092\n",
            "Epoch 477/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0092\n",
            "Epoch 478/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0092\n",
            "Epoch 479/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0092\n",
            "Epoch 480/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0092\n",
            "Epoch 481/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0092\n",
            "Epoch 482/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0092\n",
            "Epoch 483/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0092\n",
            "Epoch 484/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0092\n",
            "Epoch 485/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0092\n",
            "Epoch 486/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0092\n",
            "Epoch 487/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0092\n",
            "Epoch 488/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0060 - mean_squared_error: 0.0091\n",
            "Epoch 489/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0091\n",
            "Epoch 490/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0091\n",
            "Epoch 491/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0091\n",
            "Epoch 492/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0091\n",
            "Epoch 493/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0059 - mean_squared_error: 0.0091\n",
            "Epoch 494/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0091\n",
            "Epoch 495/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0091\n",
            "Epoch 496/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0091\n",
            "Epoch 497/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0091\n",
            "Epoch 498/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0091\n",
            "Epoch 499/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0091\n",
            "Epoch 500/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0091\n",
            "Epoch 501/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0091\n",
            "Epoch 502/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0091\n",
            "Epoch 503/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0090\n",
            "Epoch 504/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0090\n",
            "Epoch 505/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0090\n",
            "Epoch 506/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0090\n",
            "Epoch 507/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0090\n",
            "Epoch 508/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0090\n",
            "Epoch 509/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0090\n",
            "Epoch 510/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0090\n",
            "Epoch 511/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0090\n",
            "Epoch 512/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0090\n",
            "Epoch 513/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0090\n",
            "Epoch 514/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0090\n",
            "Epoch 515/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0090\n",
            "Epoch 516/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0090\n",
            "Epoch 517/1000\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_error: 0.0090\n",
            "Epoch 518/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0090\n",
            "Epoch 519/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0089\n",
            "Epoch 520/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0089\n",
            "Epoch 521/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0089\n",
            "Epoch 522/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0089\n",
            "Epoch 523/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 524/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 525/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0089\n",
            "Epoch 526/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 527/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0089\n",
            "Epoch 528/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0089\n",
            "Epoch 529/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0089\n",
            "Epoch 530/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 531/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0089\n",
            "Epoch 532/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0089\n",
            "Epoch 533/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 534/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0089\n",
            "Epoch 535/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0089\n",
            "Epoch 536/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0088\n",
            "Epoch 537/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0088\n",
            "Epoch 538/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0088\n",
            "Epoch 539/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0088\n",
            "Epoch 540/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0088\n",
            "Epoch 541/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0088\n",
            "Epoch 542/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0088\n",
            "Epoch 543/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0088\n",
            "Epoch 544/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0088\n",
            "Epoch 545/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0088\n",
            "Epoch 546/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0088\n",
            "Epoch 547/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0088\n",
            "Epoch 548/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0088\n",
            "Epoch 549/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_squared_error: 0.0088\n",
            "Epoch 550/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0088\n",
            "Epoch 551/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_squared_error: 0.0088\n",
            "Epoch 552/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0088\n",
            "Epoch 553/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0088\n",
            "Epoch 554/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 555/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_squared_error: 0.0087\n",
            "Epoch 556/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 557/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0087\n",
            "Epoch 558/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0087\n",
            "Epoch 559/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 560/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0087\n",
            "Epoch 561/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0087\n",
            "Epoch 562/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0087\n",
            "Epoch 563/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 564/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0087\n",
            "Epoch 565/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0087\n",
            "Epoch 566/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0087\n",
            "Epoch 567/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 568/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0087\n",
            "Epoch 569/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0087\n",
            "Epoch 570/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0087\n",
            "Epoch 571/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0087\n",
            "Epoch 572/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0087\n",
            "Epoch 573/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0086\n",
            "Epoch 574/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 575/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 576/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0086\n",
            "Epoch 577/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0086\n",
            "Epoch 578/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 579/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0086\n",
            "Epoch 580/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0086\n",
            "Epoch 581/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0086\n",
            "Epoch 582/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 583/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 584/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - mean_squared_error: 0.0086\n",
            "Epoch 585/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0086\n",
            "Epoch 586/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0086\n",
            "Epoch 587/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0086\n",
            "Epoch 588/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0086\n",
            "Epoch 589/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0086\n",
            "Epoch 590/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0086\n",
            "Epoch 591/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0086\n",
            "Epoch 592/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0086\n",
            "Epoch 593/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0086\n",
            "Epoch 594/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 595/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0085\n",
            "Epoch 596/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 597/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0085\n",
            "Epoch 598/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - mean_squared_error: 0.0085\n",
            "Epoch 599/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0085\n",
            "Epoch 600/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0085\n",
            "Epoch 601/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 602/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 603/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - mean_squared_error: 0.0085\n",
            "Epoch 604/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0085\n",
            "Epoch 605/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0085\n",
            "Epoch 606/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0085\n",
            "Epoch 607/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0085\n",
            "Epoch 608/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0085\n",
            "Epoch 609/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0085\n",
            "Epoch 610/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 611/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0085\n",
            "Epoch 612/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0085\n",
            "Epoch 613/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0085\n",
            "Epoch 614/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0085\n",
            "Epoch 615/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0085\n",
            "Epoch 616/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0084\n",
            "Epoch 617/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 618/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0084\n",
            "Epoch 619/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 620/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0084\n",
            "Epoch 621/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 622/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0084\n",
            "Epoch 623/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0084\n",
            "Epoch 624/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0084\n",
            "Epoch 625/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 626/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0084\n",
            "Epoch 627/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 628/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 629/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 630/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0084\n",
            "Epoch 631/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 632/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 633/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 634/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0084\n",
            "Epoch 635/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0084\n",
            "Epoch 636/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0084\n",
            "Epoch 637/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0084\n",
            "Epoch 638/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0084\n",
            "Epoch 639/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0083\n",
            "Epoch 640/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0083\n",
            "Epoch 641/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0083\n",
            "Epoch 642/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 643/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 644/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0083\n",
            "Epoch 645/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0083\n",
            "Epoch 646/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 647/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 648/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0083\n",
            "Epoch 649/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0083\n",
            "Epoch 650/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0083\n",
            "Epoch 651/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0083\n",
            "Epoch 652/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0083\n",
            "Epoch 653/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 654/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0083\n",
            "Epoch 655/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0083\n",
            "Epoch 656/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0083\n",
            "Epoch 657/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0083\n",
            "Epoch 658/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0083\n",
            "Epoch 659/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0083\n",
            "Epoch 660/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0083\n",
            "Epoch 661/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0083\n",
            "Epoch 662/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0083\n",
            "Epoch 663/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0083\n",
            "Epoch 664/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0082\n",
            "Epoch 665/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 666/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 667/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 668/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 669/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 670/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 671/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0082\n",
            "Epoch 672/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 673/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 674/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 675/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 676/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 677/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0082\n",
            "Epoch 678/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0082\n",
            "Epoch 679/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_squared_error: 0.0082\n",
            "Epoch 680/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 681/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0082\n",
            "Epoch 682/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 683/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 684/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 685/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 686/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 687/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0082\n",
            "Epoch 688/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 689/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0082\n",
            "Epoch 690/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0082\n",
            "Epoch 691/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 692/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 693/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 694/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 695/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 696/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 697/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 698/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 699/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0081\n",
            "Epoch 700/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 701/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0081\n",
            "Epoch 702/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 703/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 704/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0081\n",
            "Epoch 705/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0081\n",
            "Epoch 706/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 707/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0081\n",
            "Epoch 708/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 709/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 710/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 711/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 712/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0081\n",
            "Epoch 713/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0081\n",
            "Epoch 714/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0081\n",
            "Epoch 715/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0081\n",
            "Epoch 716/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0081\n",
            "Epoch 717/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0081\n",
            "Epoch 718/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0081\n",
            "Epoch 719/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0081\n",
            "Epoch 720/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0080\n",
            "Epoch 721/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 722/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0080\n",
            "Epoch 723/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 724/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 725/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 726/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 727/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 728/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 729/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 730/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 731/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0080\n",
            "Epoch 732/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 733/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 734/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_squared_error: 0.0080\n",
            "Epoch 735/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0080\n",
            "Epoch 736/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 737/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 738/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0080\n",
            "Epoch 739/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 740/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0059 - mean_squared_error: 0.0080\n",
            "Epoch 741/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0080\n",
            "Epoch 742/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 743/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0080\n",
            "Epoch 744/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 745/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0080\n",
            "Epoch 746/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 747/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0080\n",
            "Epoch 748/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0080\n",
            "Epoch 749/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0080\n",
            "Epoch 750/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0079\n",
            "Epoch 751/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0079\n",
            "Epoch 752/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 753/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0079\n",
            "Epoch 754/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 755/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 756/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 757/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0079\n",
            "Epoch 758/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 759/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 760/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 761/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 762/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 763/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 764/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 765/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 766/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 767/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 768/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 769/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 770/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 771/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0079\n",
            "Epoch 772/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 773/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 774/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 775/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0079\n",
            "Epoch 776/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 777/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0079\n",
            "Epoch 778/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0079\n",
            "Epoch 779/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0079\n",
            "Epoch 780/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0079\n",
            "Epoch 781/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0079\n",
            "Epoch 782/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0079\n",
            "Epoch 783/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 784/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 785/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 786/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0078\n",
            "Epoch 787/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 788/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0078\n",
            "Epoch 789/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 790/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 791/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 792/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 793/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 794/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 795/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 796/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 797/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 798/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 799/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0078\n",
            "Epoch 800/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 801/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 802/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0078\n",
            "Epoch 803/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 804/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 805/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 806/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 807/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 808/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 809/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 810/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 811/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0078\n",
            "Epoch 812/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 813/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0078\n",
            "Epoch 814/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 815/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0078\n",
            "Epoch 816/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0078\n",
            "Epoch 817/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0078\n",
            "Epoch 818/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0078\n",
            "Epoch 819/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0077\n",
            "Epoch 820/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 821/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - mean_squared_error: 0.0077\n",
            "Epoch 822/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 823/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 824/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 825/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - mean_squared_error: 0.0077\n",
            "Epoch 826/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 827/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 828/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 829/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 830/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0077\n",
            "Epoch 831/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 832/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0077\n",
            "Epoch 833/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0077\n",
            "Epoch 834/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 835/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 836/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0077\n",
            "Epoch 837/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 838/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0053 - mean_squared_error: 0.0077\n",
            "Epoch 839/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_squared_error: 0.0077\n",
            "Epoch 840/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 841/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 842/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 843/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 844/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 845/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 846/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 847/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 848/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 849/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 850/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0077\n",
            "Epoch 851/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 852/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 853/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0077\n",
            "Epoch 854/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0077\n",
            "Epoch 855/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0077\n",
            "Epoch 856/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0077\n",
            "Epoch 857/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0077\n",
            "Epoch 858/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 859/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 860/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 861/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 862/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 863/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_squared_error: 0.0076\n",
            "Epoch 864/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 865/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 866/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0076\n",
            "Epoch 867/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 868/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 869/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 870/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0076\n",
            "Epoch 871/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 872/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0076\n",
            "Epoch 873/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 874/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 875/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0076\n",
            "Epoch 876/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 877/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 878/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 879/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 880/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 881/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 882/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 883/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 884/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0076\n",
            "Epoch 885/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0059 - mean_squared_error: 0.0076\n",
            "Epoch 886/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 887/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - mean_squared_error: 0.0076\n",
            "Epoch 888/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 889/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 890/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 891/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 892/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 893/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 894/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0076\n",
            "Epoch 895/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 896/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - mean_squared_error: 0.0076\n",
            "Epoch 897/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0076\n",
            "Epoch 898/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 899/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0076\n",
            "Epoch 900/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0075\n",
            "Epoch 901/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - mean_squared_error: 0.0075\n",
            "Epoch 902/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0075\n",
            "Epoch 903/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0075\n",
            "Epoch 904/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 905/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - mean_squared_error: 0.0075\n",
            "Epoch 906/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 907/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 908/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - mean_squared_error: 0.0075\n",
            "Epoch 909/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 910/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 911/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 912/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 913/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0075\n",
            "Epoch 914/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 915/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 916/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 917/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 918/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 919/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0075\n",
            "Epoch 920/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 921/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 922/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 923/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 924/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 925/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 926/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 927/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 928/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 929/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 930/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 931/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 932/1000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 933/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 934/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 935/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 936/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 937/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 938/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 939/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 940/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 941/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0075\n",
            "Epoch 942/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 943/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 944/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0075\n",
            "Epoch 945/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0075\n",
            "Epoch 946/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 947/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 948/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 949/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 950/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 951/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 952/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 953/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_squared_error: 0.0074\n",
            "Epoch 954/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 955/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 956/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 957/1000\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_squared_error: 0.0074\n",
            "Epoch 958/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 959/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 960/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 961/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 962/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 963/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 964/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 965/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 966/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 967/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 968/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 969/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 970/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 971/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 972/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 973/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 974/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 975/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0074\n",
            "Epoch 976/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 977/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 978/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0054 - mean_squared_error: 0.0074\n",
            "Epoch 979/1000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 980/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 981/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 982/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 983/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 984/1000\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0053 - mean_squared_error: 0.0074\n",
            "Epoch 985/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 986/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 987/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_error: 0.0074\n",
            "Epoch 988/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0053 - mean_squared_error: 0.0074\n",
            "Epoch 989/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - mean_squared_error: 0.0074\n",
            "Epoch 990/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 991/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 992/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 993/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 994/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 995/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_squared_error: 0.0074\n",
            "Epoch 996/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0074\n",
            "Epoch 997/1000\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_squared_error: 0.0074\n",
            "Epoch 998/1000\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_squared_error: 0.0074\n",
            "Epoch 999/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0073\n",
            "Epoch 1000/1000\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - mean_squared_error: 0.0073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a14eab610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oTqYjvTabA_",
        "outputId": "2f9994c1-8753-4cf3-a2c9-4e5aa34154c6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 200)               47000     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 30)                3030      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 70,161\n",
            "Trainable params: 70,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "NrIZ9L9fXF72",
        "outputId": "d2595d2b-20b7-4204-c8ff-2d4617212a66"
      },
      "source": [
        "y_pred = scalerY.inverse_transform(model.predict(X_test_scaled))\n",
        "y_pred_train = scalerY.inverse_transform(model.predict(X_train_scaled))\n",
        "\n",
        "plt.scatter(y=y_test, x=y_pred,  color='gray')\n",
        "plt.show()\n",
        "\n",
        "modelResults(\"Learn metrics\", y_train, y_pred_train)\n",
        "modelResults(\"Test metrics\", y_test, y_pred)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Learn metrics\n",
            "R2: 0.8361039068133514\n",
            "RMSE: 0.9560068110867198\n",
            "NRMSE: 6.24 %\n",
            "Test metrics\n",
            "R2: 0.777920906322598\n",
            "RMSE: 1.1448537092855198\n",
            "NRMSE: 8.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSTx5D62M92V"
      },
      "source": [
        "# Czy to już wszystko?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPANHsYwNUAf"
      },
      "source": [
        "Istnieje duża liczba narzędzi, algorytmów jak i tranformacji danych, które mogą zostać zastosowane w procesie budowy modelu. Zachęcam do dalszych eksperymentów w zakresie modyfikacji parametróa jak i wprowadzania transformacji danych. Życzę samych sukcesów w Data Science. Adam Pacławski"
      ]
    }
  ]
}